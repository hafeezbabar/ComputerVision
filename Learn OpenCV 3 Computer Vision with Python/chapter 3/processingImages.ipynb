{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Images with OpenCV 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting between different color spaces\n",
    "\n",
    "- three color spaces are prevalent in modern day computer\n",
    "vision: gray, BGR, and Hue, Saturation, Value (HSV).\n",
    "\n",
    "- Gray is a color space that effectively eliminates color information translating\n",
    "to shades of gray: this color space is extremely useful for intermediate\n",
    "processing, such as face detection.\n",
    "\n",
    "- BGR is the blue-green-red color space, in which each pixel is a three-element\n",
    "array, each value representing the blue, green, and red colors: web developers\n",
    "would be familiar with a similar definition of colors, except the order of colors\n",
    "is RGB.\n",
    "\n",
    "- In HSV, hue is a color tone, saturation is the intensity of a color, and value\n",
    "represents its darkness (or brightness at the opposite end of the spectrum).\n",
    "\n",
    "- [0 255 255] value (no blue, full green, and full red) produces the yellow\n",
    "color.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Fourier Transform\n",
    "\n",
    "- Much of the processing you apply to images and videos in OpenCV involves the\n",
    "concept of Fourier Transform in some capacity.\n",
    "\n",
    "- Waveforms: useful when manipulating images, because it\n",
    "allows us to identify regions in images where a signal (such as image pixels) changes\n",
    "a lot, and regions where the change is less dramatic.  We can then arbitrarily mark\n",
    "these regions as noise or regions of interests, background or foreground, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an OpenCV context:\n",
    "- There are a number of algorithms implemented\n",
    "that enable us to process images and make sense of the data contained\n",
    "in them, and these are also reimplemented in NumPy to make our\n",
    "life even easier. NumPy has a Fast Fourier Transform (FFT) package,\n",
    "which contains the fft2() method. This method allows us to\n",
    "compute Discrete Fourier Transform (DFT) of the image.\n",
    "\n",
    "- used for common\n",
    "image processing operations, such as edge detection or line and shape detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Magnitude spectrum:\n",
    "- It gives\n",
    "a representation of the original image in terms of its changes: think of it as taking\n",
    "an image and dragging all the brightest pixels to the center. Then, you gradually\n",
    "work your way out to the border where all the darkest pixels have been pushed.\n",
    "Immediately, you will be able to see how many light and dark pixels are contained in\n",
    "your image and the percentage of their distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### High pass filter\n",
    " - A high pass filter (HPF) is a filter that examines a region of an image and boosts\n",
    "the intensity of certain pixels based on the difference in the intensity with the\n",
    "surrounding pixels.\n",
    "\n",
    "- Particularly effective in edge detection, where a common form of HPF called\n",
    "high boost filter is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "\"\"\"Note that both filters sum up to 0, the reason for this is \n",
    "    explained in detail in the Edge detection section\n",
    "\"\"\"\n",
    "\n",
    "# Filter  3 by 3\n",
    "kernel_3x3 = np.array([  [-1, -1, -1],\n",
    "                          [-1, 8, -1],\n",
    "                          [-1, -1, -1]\n",
    "                                        ])\n",
    "# Filter 5 by 5\n",
    "kernel_5x5 = np.array([  [-1, -1, -1, -1, -1],\n",
    "                          [-1, 1,  2,  1, -1],\n",
    "                          [-1, 2,  4,  2, -1],\n",
    "                          [-1, 1,  2,  1, -1],\n",
    "                          [-1, -1,  -1,  -1, -1],\n",
    "                                                ]) \n",
    "# Read the dog image\n",
    "img = cv2.imread(\"dog.jpg\", 0)    \n",
    "\n",
    "# ndimage Multidimensional Image Processiog : Filters Fourier filters Interpolation Measurements Morphology\n",
    "# convolve(): The array is convolved with the given kernel.\n",
    "k3 = ndimage.convolve(img, kernel_3x3)\n",
    "k5 = ndimage.convolve(img, kernel_5x5)\n",
    "\n",
    "blurred = cv2.GaussianBlur(img, (11,11), 0)\n",
    "g_hpf = img - blurred\n",
    "\n",
    "cv2.imshow(\"3x3\", k3)\n",
    "cv2.imshow(\"5x5\", k5)\n",
    "cv2.imshow(\"g_hpf\", g_hpf)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low pass filter\n",
    "- HPF boosts the intensity of a pixel, given its difference with its neighbors, a\n",
    "low pass filter (LPF) will smoothen the pixel if the difference with the surrounding\n",
    "pixels is lower than a certain threshold. This is used in denoising and blurring.\n",
    "\n",
    "- Gaussian blur, is a low pass filter that attenuates the intensity of high frequency signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edge Detection\n",
    "-  Humans, can\n",
    "easily recognize many object types and their pose just by seeing a backlit silhouette\n",
    "or a rough sketch. Indeed, when art emphasizes edges and poses, it often seems\n",
    "to convey the idea of an archetype, such as Rodin's The Thinker or Joe Shuster's\n",
    "Superman. \n",
    "\n",
    "- OpenCV provides many edge-finding filters, including Laplacian(), Sobel(), and\n",
    "Scharr().\n",
    "\n",
    "- OpenCV also provides many blurring filters, including blur() (simple\n",
    "average), medianBlur(), and GaussianBlur().\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Edge detection with Canny\n",
    " - The Canny edge detection algorithm is quite complex but also interesting: it's a\n",
    "five-step process that denoises the image with a Gaussian filter, calculates gradients,\n",
    "applies non maximum suppression (NMS) on edges, a double threshold on all the\n",
    "detected edges to eliminate false positives, and, lastly, analyzes all the edges and\n",
    "their connection to each other to keep the real edges and discard the weak ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"dog.jpg\", 0)\n",
    "cv2.imwrite(\"canny.jpg\", cv2.Canny(img, 200, 300))\n",
    "cv2.imshow(\"canny\", cv2.imread(\"canny.jpg\"))\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contour detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = np.zeros((200, 200), dtype=np.uint8)\n",
    "img[50:150, 50:150] = 255\n",
    "\n",
    "ret, thresh = cv2.threshold(img, 127, 255, 0)\n",
    "image, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "color = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "img = cv2.drawContours(color, contours, -1, (0,255,0), 2)\n",
    "cv2.imshow(\"contours\", color)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contours – bounding box, minimum area rectangle, and minimum enclosing circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.pyrDown(cv2.imread(\"dog.jpg\", cv2.IMREAD_UNCHANGED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, thresh = cv2.threshold(cv2.cvtColor(img.copy(), cv2.COLOR_BGR2GRAY) , 127, 255, cv2.THRESH_BINARY)\n",
    "image, contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for c in contours:\n",
    "    # find bounding box coordinates\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    # find minimum area\n",
    "    rect = cv2.minAreaRect(c)\n",
    "    # calculate coordinates of the minimum area rectangle\n",
    "    box = cv2.boxPoints(rect)\n",
    "    # normalize coordinates to integers\n",
    "    box = np.int0(box)\n",
    "    # draw contours\n",
    "    cv2.drawContours(img, [box], 0, (0,0, 255), 3)\n",
    "    # calculate center and radius of minimum enclosing circle\n",
    "    (x,y),radius = cv2.minEnclosingCircle(c)\n",
    "    # cast to integers\n",
    "    center = (int(x),int(y))\n",
    "    radius = int(radius)\n",
    "    # draw the circle\n",
    "    img = cv2.circle(img,center,radius,(0,255,0),2)\n",
    "\n",
    "cv2.drawContours(img, contours, -1, (255, 0, 0), 1)\n",
    "cv2.imshow(\"contours\", img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contours – convex contours and the Douglas-Peucker algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.01 * cv2.arcLength(cnt, True)\n",
    "approx = cv2.approxPolyDP(cnt, epsilon, True)\n",
    "\n",
    "hull = cv2.convexHull(cnt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Line and circle detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('dog.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray,50,120)\n",
    "minLineLength = 20\n",
    "maxLineGap = 5\n",
    "lines = cv2.HoughLinesP(edges,1,np.pi/180,100,minLineLength, maxLineGap)\n",
    "for x1,y1,x2,y2 in lines[0]:\n",
    "    cv2.line(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "    cv2.imshow(\"edges\", edges)\n",
    "    cv2.imshow(\"lines\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Circle detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "dog = cv2.imread('dog.jpg')\n",
    "gray_img = cv2.cvtColor(dog, cv2.COLOR_BGR2GRAY)\n",
    "img = cv2.medianBlur(gray_img, 5)\n",
    "cimg = cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)\n",
    "circles = cv2.HoughCircles(img,cv2.HOUGH_GRADIENT,1,120,\n",
    "param1=100,param2=30,minRadius=0,\n",
    "maxRadius=0)\n",
    "circles = np.uint16(np.around(circles))\n",
    "for i in circles[0,:]:\n",
    "    # draw the outer circle\n",
    "    cv2.circle(dog,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "    # draw the center of the circle\n",
    "    cv2.circle(dog,(i[0],i[1]),2,(0,0,255),3)\n",
    "    cv2.imwrite(\"dog_circles.jpg\", dog)\n",
    "    cv2.imshow(\"HoughCirlces\", dog)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "planets = cv2.imread('planets.jpg')\n",
    "gray_img = cv2.cvtColor(planets, cv2.COLOR_BGR2GRAY)\n",
    "img = cv2.medianBlur(gray_img, 5)\n",
    "cimg = cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)\n",
    "circles = cv2.HoughCircles(img,cv2.HOUGH_GRADIENT,1,120, param1=100,param2=30,minRadius=0, maxRadius=0)\n",
    "circles = np.uint16(np.around(circles))\n",
    "for i in circles[0,:]:\n",
    "    # draw the outer circle\n",
    "    cv2.circle(planets,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "    # draw the center of the circle\n",
    "    cv2.circle(planets,(i[0],i[1]),2,(0,0,255),3)\n",
    "    cv2.imwrite(\"planets_circles.jpg\", planets)\n",
    "    cv2.imshow(\"HoughCirlces\", planets)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detecting Shapes\n",
    "\n",
    "- The detection of shapes with the Hough transform is limited to circles.\n",
    "- approxPolyDP function:  This function allows the approximation of polygons, so if your\n",
    "image contains polygons, they will be quite accurately detected, combining the usage\n",
    "of cv2.findContours and cv2.approxPolyDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
